# Dá¹›iá¹£há¹­i (VisionJar) ğŸ”¥

> *Sanskrit for "Vision" or "Perception"*

An Iron Man-style visual assistant mobile app that transforms your phone into a futuristic HUD interface with real-time object detection, voice feedback, and live translation capabilities.

## ğŸš€ Features

### Current Implementation (v1.0)
- **ğŸ“± Fullscreen Camera Preview** - High-performance 30 FPS camera feed
- **ğŸ¯ Iron Man HUD Overlay** - Animated corner brackets and scanning lines
- **âœ¨ Smooth Animations** - Hardware-accelerated UI with pulsing effects
- **ğŸŒŒ Sci-Fi Design** - Orbitron font and cyan neon aesthetics
- **ğŸ“ Landscape Mode** - Optimized for immersive experience

### Planned Features (Roadmap)
- **ğŸ¤– Real-time Object Detection** - ML Kit integration for instant object recognition
- **ğŸ—£ï¸ Jarvis-style Voice Feedback** - TTS announcements of detected objects
- **ğŸŒ Multi-language Translation** - Sanskrit/English/Hindi live translation
- **ğŸ”„ Mode Switching** - Object Mode, Text Mode, Plant Mode
- **ğŸ­ Face Recognition** - Identify known faces with emotion detection
- **ğŸ§  GPT-4 Vision Integration** - Deep insights and analysis

## ğŸ› ï¸ Tech Stack

- **Framework**: Flutter (Dart)
- **Camera**: Flutter Camera Plugin
- **ML/AI**: Google ML Kit, TensorFlow Lite
- **Voice**: Flutter TTS
- **Translation**: Google Translate API
- **Fonts**: Google Fonts (Orbitron)
- **Platform**: Android & iOS

## ğŸ“‹ Prerequisites

- Flutter SDK (3.7.2 or higher)
- Android Studio / VS Code
- Android device with camera
- Developer mode enabled on device

## ğŸš€ Quick Start

1. **Clone the repository**
   ```bash
   git clone https://github.com/Rishab-Kumar09/Drishti.git
   cd Drishti
   ```

2. **Install dependencies**
   ```bash
   flutter pub get
   ```

3. **Run the app**
   ```bash
   flutter run
   ```

## ğŸ“± Screenshots

*Coming soon - Iron Man HUD interface in action!*

## ğŸ¯ Performance Targets

- **Detection Latency**: < 300ms per frame
- **Object Recognition**: 80%+ accuracy on common objects
- **Translation Speed**: < 1 second per word/phrase
- **Wow Factor**: Users say "Whoa that's cool!" âœ¨

## ğŸ”§ Development Setup

### Android Configuration
- **Min SDK**: 21
- **Target SDK**: 33
- **NDK Version**: 27.0.12077973
- **Permissions**: Camera, Hardware Camera, Autofocus

### Dependencies
```yaml
dependencies:
  flutter: sdk: flutter
  camera: ^0.11.2
  google_mlkit_object_detection: ^0.15.0
  flutter_tts: ^4.2.3
  google_mlkit_translation: ^0.13.0
  google_fonts: ^6.2.1
```

## ğŸ—ï¸ Architecture

```
lib/
â”œâ”€â”€ main.dart              # App entry point & camera setup
â”œâ”€â”€ screens/
â”‚   â””â”€â”€ camera_screen.dart # Main camera interface
â”œâ”€â”€ widgets/
â”‚   â””â”€â”€ hud_painter.dart   # Custom HUD overlay
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ml_service.dart    # ML Kit integration
â”‚   â”œâ”€â”€ tts_service.dart   # Text-to-speech
â”‚   â””â”€â”€ translation_service.dart # Translation API
â””â”€â”€ models/
    â””â”€â”€ detection_result.dart # Data models
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Inspired by Iron Man's JARVIS interface
- Built with Flutter's powerful camera capabilities
- Powered by Google's ML Kit for object detection


